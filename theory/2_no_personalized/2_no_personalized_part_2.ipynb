{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>Updated February 2023 - This notebook was created by [Santi Seguí](https://ssegui.github.io/). </i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item association recommendation\n",
    "### Example:\n",
    "<img src=\"images/np3.png\" width=70%>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different items 171\n",
      "Number of rows  9835\n",
      "An example: ['pip fruit', 'yogurt', 'cream cheese ', 'meat spreads']\n"
     ]
    }
   ],
   "source": [
    "#Let's read a dataset which contains several market baskets lists\n",
    "\n",
    "# read data/grocieries.csv\n",
    "def union(a, b):\n",
    "    \"\"\" return the union of two lists \"\"\"\n",
    "    return list(set(a) | set(b))\n",
    "\n",
    "market_data = []\n",
    "cont = 0\n",
    "items = []\n",
    "with open(\"./data/groceries.csv\") as f:\n",
    "    for l in f:\n",
    "        market_data.append(l.rstrip().split(','))\n",
    "        items = union(items,l.rstrip().split(','))\n",
    "\n",
    "print(\"Number of different items\", len(items))\n",
    "print(\"Number of rows \", len(market_data))\n",
    "\n",
    "\n",
    "print(\"An example:\", market_data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most simple ways to found association between product could be obtained as follows: $$score(Y|X) = \\frac{X \\ and \\ Y}{X}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which is the top associated product with \"yogurt\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Which is the top associated product with \"yogurt\"?\n",
    "def top_associated_products(dataset, product, N = 5):\n",
    "    d = defaultdict(lambda: 0) # dictionary for the items \n",
    "    product_times = 0\n",
    "    for basket in dataset: # for each basket case \n",
    "        if product in basket:  # for those who contains the product\n",
    "            product_times += 1\n",
    "            for i in basket:   # x and y together\n",
    "                if i != product: \n",
    "                    d[i] += 1  \n",
    "    for k in d:\n",
    "        d[k] =   float(d[k] / product_times) # (X and Y) / X\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.40160349854227406), ('other vegetables', 0.3112244897959184), ('rolls/buns', 0.24635568513119532)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products(market_data, 'yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about with \"rice\"? and with \"rum\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.6133333333333333), ('other vegetables', 0.52), ('root vegetables', 0.41333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "print(top_associated_products(market_data, 'rice',N = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.38636363636363635), ('other vegetables', 0.3409090909090909), ('tropical fruit', 0.20454545454545456)]\n"
     ]
    }
   ],
   "source": [
    "print(top_associated_products(market_data, 'rum',N = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens? \n",
    "Is it a good measure? It has a problem with popular items...\n",
    "<br>\n",
    "Let's check this other formula:\n",
    "$$score(Y|X) = \\frac{ \\frac{X \\ and \\ Y}{X}} {  \\frac{!X \\ and \\ Y}{!X} }  $$\n",
    "\n",
    "$!X$ meaning when it is not present in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_associated_products2(dataset, product,N = 5):\n",
    "    d = defaultdict(lambda: 0) # dictionary for the items \n",
    "    nd = defaultdict(lambda: 0) # dictionary for the items absence \n",
    "    product_times = 0 # X\n",
    "    nproduct_times = 0\n",
    "    for basket in dataset: # for each basket case \n",
    "        if product in basket:  # for those who contains the product\n",
    "            product_times += 1\n",
    "            for i in basket:   # x and y together\n",
    "                if i != product: \n",
    "                    d[i] += 1\n",
    "        else:\n",
    "            nproduct_times += 1\n",
    "            for i in basket:\n",
    "                nd[i] += 1\n",
    "            \n",
    "    for k in d:\n",
    "        try:\n",
    "            d[k] =   float(d[k] / product_times) / float(nd[k] / nproduct_times) # (X and Y) / X / (!X and Y) / !X\n",
    "        except ZeroDivisionError:\n",
    "            d[k] = 0\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kitchen utensil', 6.168367346938775), ('preservation products', 6.168367346938775), ('meat spreads', 4.626275510204082)]\n",
      "[('decalcifier', 20.020512820512824), ('canned fruit', 18.590476190476192), ('organic products', 18.590476190476192)]\n",
      "[('artif. sweetener', 14.834848484848484), ('specialty vegetables', 13.907670454545455), ('cooking chocolate', 9.271780303030305)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products2(market_data, 'yogurt',N = 3)\n",
    "print(s)\n",
    "\n",
    "s = top_associated_products2(market_data, 'rice',N = 3)\n",
    "print(s)\n",
    "\n",
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products2(market_data, 'rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crap as well when the Y is unpopular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check this last formula:\n",
    "$$ score(Y|X) = \\frac{P(X \\ and \\ Y)}{P(X)P(Y) }   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_associated_products3(dataset, product,N = 5):\n",
    "    d = defaultdict(lambda: 0) # dictionary for the items \n",
    "    nd = defaultdict(lambda: 0) # dictionary for the items \n",
    "    product_times = 0\n",
    "    for basket in dataset: # for each basket case \n",
    "        if product in basket:  # for those who contains the product X in the basket\n",
    "            product_times += 1\n",
    "            for i in basket:   # x and y together\n",
    "                if i != product: \n",
    "                    d[i] += 1\n",
    "        \n",
    "        for i in (i for i in basket if i != product):\n",
    "            nd[i] += 1\n",
    "            \n",
    "    for k in d:\n",
    "        d[k] =   float(d[k] / nd[k] * product_times) # (X and Y) / X\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('baby food', 1372.0), ('kitchen utensil', 686.0), ('preservation products', 686.0)]\n",
      "[('decalcifier', 10.0), ('canned fruit', 9.375), ('organic products', 9.375)]\n",
      "[('artif. sweetener', 2.75), ('specialty vegetables', 2.588235294117647), ('cooking chocolate', 1.76)]\n"
     ]
    }
   ],
   "source": [
    "print(top_associated_products3(market_data,'yogurt',N = 3))\n",
    "print(top_associated_products3(market_data,'rice',N = 3))\n",
    "print(top_associated_products3(market_data,'rum',N = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice: Let's apply Association Rules on MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2201/3135533698.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users = pd.read_csv('./data/ml-1m/users.dat', sep='::', names=u_cols)\n",
      "/tmp/ipykernel_2201/3135533698.py:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_csv('./data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
      "/tmp/ipykernel_2201/3135533698.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies = pd.read_csv('./data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La BD has 1000209 ratings\n",
      "La BD has  6040  users\n",
      "La BD has  3706  movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                   title  movie_id  rating  \\\n",
       "0        1  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "1        2  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "2       12  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "3       15  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "4       17  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "\n",
       "  release_date  sex age  \n",
       "0        Drama    1   F  \n",
       "1        Drama   56   M  \n",
       "2        Drama   25   M  \n",
       "3        Drama   25   M  \n",
       "4        Drama   50   M  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NETFLIX REAL 50.000.000 usuaris and 100.000 items\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('./data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date',]\n",
    "movies = pd.read_csv('./data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# Construcció del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "n_users = data.user_id.nunique()\n",
    "n_items = data.movie_id.nunique()\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", n_users,\" users\")\n",
    "print(\"La BD has \", n_items, \" movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert dataset\n",
    "\n",
    "movies_data = []\n",
    "for user_id in data.user_id.unique():\n",
    "    movies_data.append(list(data[data.user_id == user_id].title.values))\n",
    "\n",
    "with open('data/movies_data.csv', 'w') as movies_csv:\n",
    "    for user_movies in movies_data:\n",
    "        movies_csv.write(';'.join(user_movies))\n",
    "        movies_csv.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply previous methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Star Wars: Episode V - The Empire Strikes Back (1980)', 0.7873620862587764),\n",
       " ('Star Wars: Episode VI - Return of the Jedi (1983)', 0.706452691407556),\n",
       " ('Raiders of the Lost Ark (1981)', 0.6593112671347375)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_associated_products(movies_data, \"Star Wars: Episode IV - A New Hope (1977)\", N = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American Beauty (1999)', 0.6788405797101449),\n",
       " ('Star Wars: Episode V - The Empire Strikes Back (1980)', 0.6533333333333333),\n",
       " ('Star Wars: Episode IV - A New Hope (1977)', 0.6521739130434783)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_associated_products(movies_data, \"One Flew Over the Cuckoo's Nest (1975)\", N = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Last Dance (1996)', 20.01159420289855),\n",
       " ('Loaded (1994)', 20.01159420289855),\n",
       " ('Jamaica Inn (1939)', 17.51014492753623)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_associated_products2(movies_data, \"One Flew Over the Cuckoo's Nest (1975)\", N = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Country Life (1994)', 1725.0),\n",
       " ('Sunchaser, The (1996)', 1725.0),\n",
       " ('Mouth to Mouth (Boca a boca) (1995)', 1725.0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_associated_products3(movies_data, \"One Flew Over the Cuckoo's Nest (1975)\", N = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: the algorithms 2 & 3 seems to be better than the 1st (even though they seem to work better with popular items; not extremely unpopular ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APRIORI Algorithm\n",
    "Typically, association rules are considered interesting if they satisfy both a minimum support threshold and a minimum confidence threshold\n",
    "\n",
    "![alt apriori](images/apriori.png)\n",
    "\n",
    "<b>Apriori principle</b>: Any subset of a frequent itemset must be frequent\n",
    "\n",
    "> Step 1: Find the frequent itemsset: the set of items that have minimum support.\n",
    "> -  A subset of a frequent itemset must also be a frequent itemset  i.e. if {1,2} is a frequent itemset, both {1} and {2} should be a frequent itemset\n",
    "> - Iteratively find frequent itemsets with cardinality from 1 to k (k-itemset)\n",
    "\n",
    "> Step 2: Use the frequent itemsets to generate association rules\n",
    "\n",
    "![alt apriori2](images/apriori2.png)\n",
    "\n",
    "Reference : \n",
    "[Fast algorithms for mining association rules](http://www-cgi.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ngm/15-721/summaries/12.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def dataFromFile(fname, sep: str = ','):\n",
    "    \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "    file_iter = open(fname, 'r')\n",
    "    for line in file_iter:\n",
    "        line = line.strip().rstrip(sep)                         # Remove trailing comma\n",
    "        record = frozenset(line.split(sep))\n",
    "        yield record\n",
    "                \n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    \"\"\"Generate 1-itemSets\"\"\"\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))              # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "                \n",
    "def apriori(data_iterator, min_support, min_confidence, method = 'confidence'):\n",
    "    \"\"\"A-priori method\"\"\"\n",
    "    def returnItemsWithMinSupport(itemSet, transactionList, min_support, freqSet):\n",
    "        \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "       of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "        _itemSet = set()\n",
    "        localSet = defaultdict(int)\n",
    "\n",
    "        for item in itemSet:\n",
    "                for transaction in transactionList:\n",
    "                        if item.issubset(transaction):\n",
    "                                freqSet[item] += 1\n",
    "                                localSet[item] += 1\n",
    "\n",
    "        for item, count in localSet.items():\n",
    "                support = float(count)/len(transactionList)\n",
    "\n",
    "                if support >= min_support:\n",
    "                        _itemSet.add(item)\n",
    "\n",
    "        return _itemSet\n",
    "    \n",
    "    def joinSet(itemSet, length):\n",
    "        \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "        return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])\n",
    "    \n",
    "    def getSupport(item):\n",
    "        \"\"\"local function which Returns the support of an item\"\"\"\n",
    "        return float(freqSet[item])/len(transactionList)\n",
    "    \n",
    "    def subsets(arr):\n",
    "        \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "        return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "    \n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iterator)\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy min_support\n",
    "    \n",
    "    assocRules = dict()\n",
    "    \n",
    "    # Step 1: Find the frequent itemsset: the set of items that have minimum support.\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet,transactionList,min_support,freqSet)\n",
    "    currentLSet = oneCSet\n",
    "    \n",
    "    k = 2\n",
    "    while(currentLSet != set([])): # while there is pontential new associations\n",
    "        largeSet[k-1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(currentLSet,transactionList,min_support, freqSet)\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "    \n",
    "    toRetItems = []\n",
    "    for key, value in list(largeSet.items()):\n",
    "        toRetItems.extend([(tuple(item), getSupport(item))\n",
    "                           for item in value])\n",
    "\n",
    "\n",
    "    ## Step 2: Use the frequent itemsets to generate association rules\n",
    "    toRetRules = defaultdict(lambda: [])\n",
    "    for key in list(largeSet.keys()):\n",
    "        if key!=1: #for itemsets with two or more elements\n",
    "            for item in largeSet[key]:\n",
    "                for element in item:\n",
    "                    remain = item-frozenset([element])\n",
    "                    if method == 'confidence':\n",
    "                        confidence = getSupport(item)/getSupport(remain)\n",
    "                    elif method == 'lift':\n",
    "                        confidence = getSupport(item)/(getSupport(remain)*getSupport(frozenset([element]))) ## lift\n",
    "                        #print(\"NOT IMPLEMENTED\")\n",
    "                        #return [],[] \n",
    "                    else:\n",
    "                        print(\"Not Valid Method\")\n",
    "                        return [],[] \n",
    "                    \n",
    "                    if confidence >= min_confidence:\n",
    "                        toRetRules[tuple(remain)].append((tuple([element]),confidence))\n",
    "    \n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "def printResults(items, rules, only_rules = True):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    if(len(items)>0):\n",
    "        if(only_rules ==False):\n",
    "            for item, support in sorted(items, key = lambda x: float(x[1])):\n",
    "                print(\"item: %s , %.3f\" % (str(item), support))\n",
    "        print(\"\\n------------------------ RULES:\")\n",
    "        for pre, post in sorted([(key, v) for key,values in rules.items() for v in values ],\n",
    "                                       key=lambda x: float(x[1][1])):\n",
    "            print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post[0]), post[1]))\n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------ RULES:\n",
      "Rule: ('rolls/buns',) ==> ('whole milk',) , 0.308\n",
      "Rule: ('berries',) ==> ('other vegetables',) , 0.309\n",
      "Rule: ('whole milk', 'other vegetables') ==> ('root vegetables',) , 0.310\n",
      "Rule: ('bottled water',) ==> ('whole milk',) , 0.311\n",
      "Rule: ('yogurt',) ==> ('other vegetables',) , 0.311\n",
      "Rule: ('dessert',) ==> ('other vegetables',) , 0.312\n",
      "Rule: ('whole milk', 'bottled water') ==> ('other vegetables',) , 0.314\n",
      "Rule: ('rolls/buns', 'whole milk') ==> ('other vegetables',) , 0.316\n",
      "Rule: ('berries',) ==> ('yogurt',) , 0.318\n",
      "Rule: ('whole milk', 'pastry') ==> ('other vegetables',) , 0.318\n",
      "Rule: ('sausage',) ==> ('whole milk',) , 0.318\n",
      "Rule: ('sugar',) ==> ('other vegetables',) , 0.318\n",
      "Rule: ('coffee',) ==> ('whole milk',) , 0.322\n",
      "Rule: ('curd',) ==> ('other vegetables',) , 0.323\n",
      "Rule: ('curd',) ==> ('yogurt',) , 0.324\n",
      "Rule: ('cream cheese ',) ==> ('yogurt',) , 0.325\n",
      "Rule: ('sausage',) ==> ('rolls/buns',) , 0.326\n",
      "Rule: ('frankfurter',) ==> ('rolls/buns',) , 0.326\n",
      "Rule: ('white bread',) ==> ('other vegetables',) , 0.326\n",
      "Rule: ('waffles',) ==> ('whole milk',) , 0.331\n",
      "Rule: ('beef',) ==> ('root vegetables',) , 0.331\n",
      "Rule: ('rolls/buns', 'yogurt') ==> ('other vegetables',) , 0.334\n",
      "Rule: ('chocolate',) ==> ('whole milk',) , 0.336\n",
      "Rule: ('citrus fruit', 'whole milk') ==> ('yogurt',) , 0.337\n",
      "Rule: ('margarine',) ==> ('other vegetables',) , 0.337\n",
      "Rule: ('whipped/sour cream', 'whole milk') ==> ('yogurt',) , 0.338\n",
      "Rule: ('whole milk', 'sausage') ==> ('other vegetables',) , 0.340\n",
      "Rule: ('tropical fruit',) ==> ('other vegetables',) , 0.342\n",
      "Rule: ('newspapers',) ==> ('whole milk',) , 0.343\n",
      "Rule: ('tropical fruit', 'other vegetables') ==> ('yogurt',) , 0.343\n",
      "Rule: ('tropical fruit', 'other vegetables') ==> ('root vegetables',) , 0.343\n",
      "Rule: ('pip fruit',) ==> ('other vegetables',) , 0.345\n",
      "Rule: ('whole milk', 'soda') ==> ('other vegetables',) , 0.348\n",
      "Rule: ('frankfurter',) ==> ('whole milk',) , 0.348\n",
      "Rule: ('citrus fruit',) ==> ('other vegetables',) , 0.349\n",
      "Rule: ('domestic eggs',) ==> ('other vegetables',) , 0.351\n",
      "Rule: ('whipped/sour cream', 'other vegetables') ==> ('yogurt',) , 0.352\n",
      "Rule: ('cream cheese ',) ==> ('other vegetables',) , 0.352\n",
      "Rule: ('berries',) ==> ('whole milk',) , 0.355\n",
      "Rule: ('tropical fruit', 'whole milk') ==> ('yogurt',) , 0.358\n",
      "Rule: ('citrus fruit', 'other vegetables') ==> ('root vegetables',) , 0.359\n",
      "Rule: ('long life bakery product',) ==> ('whole milk',) , 0.361\n",
      "Rule: ('butter',) ==> ('other vegetables',) , 0.361\n",
      "Rule: ('fruit/vegetable juice',) ==> ('whole milk',) , 0.368\n",
      "Rule: ('citrus fruit',) ==> ('whole milk',) , 0.369\n",
      "Rule: ('dessert',) ==> ('whole milk',) , 0.370\n",
      "Rule: ('frozen vegetables',) ==> ('other vegetables',) , 0.370\n",
      "Rule: ('butter milk',) ==> ('other vegetables',) , 0.371\n",
      "Rule: ('pastry',) ==> ('whole milk',) , 0.374\n",
      "Rule: ('pork',) ==> ('other vegetables',) , 0.376\n",
      "Rule: ('beef',) ==> ('other vegetables',) , 0.376\n",
      "Rule: ('napkins',) ==> ('whole milk',) , 0.377\n",
      "Rule: ('sausage', 'other vegetables') ==> ('whole milk',) , 0.377\n",
      "Rule: ('yogurt', 'soda') ==> ('whole milk',) , 0.383\n",
      "Rule: ('pork',) ==> ('whole milk',) , 0.384\n",
      "Rule: ('curd', 'whole milk') ==> ('yogurt',) , 0.385\n",
      "Rule: ('other vegetables',) ==> ('whole milk',) , 0.387\n",
      "Rule: ('brown bread',) ==> ('whole milk',) , 0.389\n",
      "Rule: ('hygiene articles',) ==> ('whole milk',) , 0.389\n",
      "Rule: ('onions',) ==> ('whole milk',) , 0.390\n",
      "Rule: ('fruit/vegetable juice', 'whole milk') ==> ('other vegetables',) , 0.393\n",
      "Rule: ('whole milk', 'yogurt') ==> ('other vegetables',) , 0.397\n",
      "Rule: ('pip fruit',) ==> ('whole milk',) , 0.398\n",
      "Rule: ('yogurt',) ==> ('whole milk',) , 0.402\n",
      "Rule: ('oil',) ==> ('whole milk',) , 0.402\n",
      "Rule: ('whipped/sour cream',) ==> ('other vegetables',) , 0.403\n",
      "Rule: ('tropical fruit',) ==> ('whole milk',) , 0.403\n",
      "Rule: ('tropical fruit', 'whole milk') ==> ('other vegetables',) , 0.404\n",
      "Rule: ('beef',) ==> ('whole milk',) , 0.405\n",
      "Rule: ('white bread',) ==> ('whole milk',) , 0.406\n",
      "Rule: ('chicken',) ==> ('whole milk',) , 0.410\n",
      "Rule: ('domestic eggs', 'whole milk') ==> ('other vegetables',) , 0.410\n",
      "Rule: ('hard cheese',) ==> ('whole milk',) , 0.411\n",
      "Rule: ('margarine',) ==> ('whole milk',) , 0.413\n",
      "Rule: ('butter milk',) ==> ('whole milk',) , 0.415\n",
      "Rule: ('hamburger meat',) ==> ('other vegetables',) , 0.416\n",
      "Rule: ('whole milk', 'butter') ==> ('other vegetables',) , 0.417\n",
      "Rule: ('chicken',) ==> ('other vegetables',) , 0.417\n",
      "Rule: ('rolls/buns', 'other vegetables') ==> ('whole milk',) , 0.420\n",
      "Rule: ('tropical fruit', 'yogurt') ==> ('other vegetables',) , 0.420\n",
      "Rule: ('frozen vegetables',) ==> ('whole milk',) , 0.425\n",
      "Rule: ('other vegetables', 'soda') ==> ('whole milk',) , 0.425\n",
      "Rule: ('cream cheese ',) ==> ('whole milk',) , 0.426\n",
      "Rule: ('whole milk', 'citrus fruit') ==> ('other vegetables',) , 0.427\n",
      "Rule: ('other vegetables', 'bottled water') ==> ('whole milk',) , 0.434\n",
      "Rule: ('root vegetables',) ==> ('other vegetables',) , 0.435\n",
      "Rule: ('sliced cheese',) ==> ('whole milk',) , 0.440\n",
      "Rule: ('ham',) ==> ('whole milk',) , 0.441\n",
      "Rule: ('hamburger meat',) ==> ('whole milk',) , 0.443\n",
      "Rule: ('sugar',) ==> ('whole milk',) , 0.444\n",
      "Rule: ('rolls/buns', 'tropical fruit') ==> ('whole milk',) , 0.446\n",
      "Rule: ('root vegetables',) ==> ('whole milk',) , 0.449\n",
      "Rule: ('whole milk', 'pip fruit') ==> ('other vegetables',) , 0.449\n",
      "Rule: ('whipped/sour cream',) ==> ('whole milk',) , 0.450\n",
      "Rule: ('citrus fruit', 'other vegetables') ==> ('whole milk',) , 0.451\n",
      "Rule: ('rolls/buns', 'yogurt') ==> ('whole milk',) , 0.453\n",
      "Rule: ('whipped/sour cream', 'whole milk') ==> ('other vegetables',) , 0.454\n",
      "Rule: ('pork', 'whole milk') ==> ('other vegetables',) , 0.459\n",
      "Rule: ('onions',) ==> ('other vegetables',) , 0.459\n",
      "Rule: ('other vegetables', 'pastry') ==> ('whole milk',) , 0.468\n",
      "Rule: ('pork', 'other vegetables') ==> ('whole milk',) , 0.469\n",
      "Rule: ('domestic eggs',) ==> ('whole milk',) , 0.473\n",
      "Rule: ('whole milk', 'root vegetables') ==> ('other vegetables',) , 0.474\n",
      "Rule: ('citrus fruit', 'yogurt') ==> ('whole milk',) , 0.474\n",
      "Rule: ('tropical fruit', 'other vegetables') ==> ('whole milk',) , 0.476\n",
      "Rule: ('other vegetables', 'root vegetables') ==> ('whole milk',) , 0.489\n",
      "Rule: ('whipped/sour cream', 'yogurt') ==> ('other vegetables',) , 0.490\n",
      "Rule: ('curd',) ==> ('whole milk',) , 0.490\n",
      "Rule: ('butter',) ==> ('whole milk',) , 0.497\n",
      "Rule: ('fruit/vegetable juice', 'other vegetables') ==> ('whole milk',) , 0.498\n",
      "Rule: ('root vegetables', 'yogurt') ==> ('other vegetables',) , 0.500\n",
      "Rule: ('rolls/buns', 'root vegetables') ==> ('other vegetables',) , 0.502\n",
      "Rule: ('whipped/sour cream', 'other vegetables') ==> ('whole milk',) , 0.507\n",
      "Rule: ('other vegetables', 'yogurt') ==> ('whole milk',) , 0.513\n",
      "Rule: ('tropical fruit', 'yogurt') ==> ('whole milk',) , 0.517\n",
      "Rule: ('pip fruit', 'other vegetables') ==> ('whole milk',) , 0.518\n",
      "Rule: ('rolls/buns', 'root vegetables') ==> ('whole milk',) , 0.523\n",
      "Rule: ('whipped/sour cream', 'yogurt') ==> ('whole milk',) , 0.525\n",
      "Rule: ('domestic eggs', 'other vegetables') ==> ('whole milk',) , 0.553\n",
      "Rule: ('root vegetables', 'yogurt') ==> ('whole milk',) , 0.563\n",
      "Rule: ('tropical fruit', 'root vegetables') ==> ('whole milk',) , 0.570\n",
      "Rule: ('other vegetables', 'butter') ==> ('whole milk',) , 0.574\n",
      "Rule: ('curd', 'yogurt') ==> ('whole milk',) , 0.582\n",
      "Rule: ('tropical fruit', 'root vegetables') ==> ('other vegetables',) , 0.585\n",
      "Rule: ('citrus fruit', 'root vegetables') ==> ('other vegetables',) , 0.586\n"
     ]
    }
   ],
   "source": [
    "inFile = dataFromFile('./data/groceries.csv')\n",
    "min_support = 0.01\n",
    "min_confidence = 0.3\n",
    "items, rules =  apriori(inFile, min_support, min_confidence)\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yogurt -> [(('whole milk',), 0.40160349854227406), (('other vegetables',), 0.3112244897959184)]\n",
      "chicken -> [(('other vegetables',), 0.4170616113744075), (('whole milk',), 0.4099526066350711)]\n",
      "napkins -> [(('whole milk',), 0.37669902912621356)]\n"
     ]
    }
   ],
   "source": [
    "print('yogurt ->', rules[tuple(frozenset(['yogurt']))])\n",
    "print('chicken ->', rules[tuple(frozenset(['chicken']))])\n",
    "print('napkins ->', rules[tuple(frozenset(['napkins']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check it with LIFT \n",
    "inFile = dataFromFile('./data/groceries.csv')\n",
    "min_support = 0.01\n",
    "min_confidence = 1.8\n",
    "items, rules =  apriori(inFile, min_support, min_confidence, method = 'lift')\n",
    "#printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yogurt -> [(('berries',), 2.279847718904075), (('butter',), 1.894027335704924), (('frozen vegetables',), 1.8489235017474217), (('citrus fruit',), 1.8757521436092863), (('tropical fruit',), 2.0004746084480303), (('cream cheese ',), 2.3306986729117876), (('whipped/sour cream',), 2.0742509769865394), (('fruit/vegetable juice',), 1.8551049111627773), (('curd',), 2.325615360648076)]\n",
      "chicken -> [(('other vegetables',), 2.1554392789633727), (('root vegetables',), 2.32622064440829)]\n",
      "napkins -> [(('tropical fruit',), 1.831988033416121)]\n"
     ]
    }
   ],
   "source": [
    "print('yogurt ->', rules[tuple(frozenset(['yogurt']))])\n",
    "print('chicken ->', rules[tuple(frozenset(['chicken']))])\n",
    "print('napkins ->', rules[tuple(frozenset(['napkins']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-success\"><b>Exercice: Create and Product Association Recommender with MovieLens Dataset</b><p>\n",
    "Explain the obtained results and conclusions.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check it with LIFT \n",
    "inFile = dataFromFile('./data/movies_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2201/4191242657.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmin_support\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmin_confidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mapriori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_confidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lift'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#printResults(items, rules)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2201/519006006.py\u001b[0m in \u001b[0;36mapriori\u001b[0;34m(data_iterator, min_support, min_confidence, method)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Step 1: Find the frequent itemsset: the set of items that have minimum support.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0moneCSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturnItemsWithMinSupport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransactionList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreqSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mcurrentLSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moneCSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2201/519006006.py\u001b[0m in \u001b[0;36mreturnItemsWithMinSupport\u001b[0;34m(itemSet, transactionList, min_support, freqSet)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitemSet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransactionList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                                 \u001b[0mfreqSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                 \u001b[0mlocalSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_support = 0.1\n",
    "min_confidence = 1.8\n",
    "items, rules =  apriori(inFile, min_support, min_confidence, method = 'lift')\n",
    "#printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rebel Without a Cause (1955) ->', rules[tuple(frozenset(['Rebel Without a Cause (1955)']))])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
